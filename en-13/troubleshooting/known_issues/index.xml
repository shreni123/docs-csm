<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Known Issues on Cray System Management (CSM)</title>
    <link>/docs-csm/en-13/troubleshooting/known_issues/</link>
    <description>Recent content in Known Issues on Cray System Management (CSM)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Sun, 11 Sep 2022 03:48:14 +0000</lastBuildDate><atom:link href="/docs-csm/en-13/troubleshooting/known_issues/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>/docs-csm/en-13/troubleshooting/known_issues/wait_for_unbound_hang/</link>
      <pubDate>Sun, 11 Sep 2022 03:48:08 +0000</pubDate>
      
      <guid>/docs-csm/en-13/troubleshooting/known_issues/wait_for_unbound_hang/</guid>
      <description>#Wait_for_unbound or cray-dns-unbound-manager hangs
  Run the following command:
kubectl get jobs -n services | grep cray-dns-unbound-manager services cray-dns-unbound-manager-1635352560 0/1 26h 26h services cray-dns-unbound-manager-1635448680 1/1 35s 8m37s services cray-dns-unbound-manager-1635448860 1/1 51s 5m36s services cray-dns-unbound-manager-1635449040 1/1 61s 2m35s    If you see one of the jobs show 0/1 for more than 10 minutes and there are other runs with 1/1. That means that job is hung. You can delete the job with:</description>
    </item>
    
    <item>
      <title>Known Issues With NCN Resource Checks</title>
      <link>/docs-csm/en-13/troubleshooting/known_issues/ncn_resource_checks/</link>
      <pubDate>Sun, 11 Sep 2022 03:48:08 +0000</pubDate>
      
      <guid>/docs-csm/en-13/troubleshooting/known_issues/ncn_resource_checks/</guid>
      <description>Known issues with NCN resource checks   pods_not_running
  If the output of pods_not_running indicates that there are pods in the Evicted state, it may be because of the root file system being filled up on the Kubernetes node in question. Kubernetes will begin evicting pods once the root file system space is at 85% full, and will continue to evict them until it is back under 80%. This commonly happens on ncn-m001, because it is a location where install and documentation files may have been downloaded.</description>
    </item>
    
    <item>
      <title>Kubernetes Master Or Worker Node&#39;s Root Filesystem Is Out Of Space</title>
      <link>/docs-csm/en-13/troubleshooting/known_issues/kubernetes_node_rootfs_out_of_space/</link>
      <pubDate>Sun, 11 Sep 2022 03:48:08 +0000</pubDate>
      
      <guid>/docs-csm/en-13/troubleshooting/known_issues/kubernetes_node_rootfs_out_of_space/</guid>
      <description>Kubernetes Master or Worker node&amp;rsquo;s root filesystem is out of space Description There is a known bug in Kubernetes 1.19.9 where movement of a pod with an attached volume may not complete in time and cause the kubelet service to stream error messages to the /var/log/messages log file. If this goes unchecked, it will fill up the root file system.
Fix   Log into the node that has space issues.</description>
    </item>
    
    <item>
      <title>Mellanox Lacp-individual Limitations</title>
      <link>/docs-csm/en-13/troubleshooting/known_issues/mellanox_lacp_individual/</link>
      <pubDate>Sun, 11 Sep 2022 03:48:08 +0000</pubDate>
      
      <guid>/docs-csm/en-13/troubleshooting/known_issues/mellanox_lacp_individual/</guid>
      <description>Mellanox lacp-individual limitations Description In some failover/maintenance scenarios admins may want to shutdown one port of the bond on an NCN. Due to the way Mellanox handles lacp-individual mode the ports need to be shutdown from the switch instead of the NCN.
Fix Shut down the port on the switch instead of the NCN.</description>
    </item>
    
    <item>
      <title>Software Management Services Health Checks</title>
      <link>/docs-csm/en-13/troubleshooting/known_issues/sms_health_check/</link>
      <pubDate>Sun, 11 Sep 2022 03:48:08 +0000</pubDate>
      
      <guid>/docs-csm/en-13/troubleshooting/known_issues/sms_health_check/</guid>
      <description>Software Management Services health checks  SMS test execution Interpreting cmsdev Results Known issues with SMS tests  3.1 SMS test execution The test in this section requires that the Cray CLI is configured on nodes where the test is executed.
The following test can be run on any Kubernetes node (any master or worker node, but not on the PIT node).
/usr/local/bin/cmsdev test -q all  The cmsdev tool logs to /opt/cray/tests/cmsdev.</description>
    </item>
    
    <item>
      <title>Spire Database Cluster DNS Lookup Failure</title>
      <link>/docs-csm/en-13/troubleshooting/known_issues/spire_database_lookup_error/</link>
      <pubDate>Sun, 11 Sep 2022 03:48:08 +0000</pubDate>
      
      <guid>/docs-csm/en-13/troubleshooting/known_issues/spire_database_lookup_error/</guid>
      <description>Spire Database Cluster DNS Lookup Failure Description There is a known issue where if Unbound is configured to forward to an invalid or inaccessible site DNS server, the Spire server may be unable to resolve the hostname of its PostgreSQL cluster.
Symptoms   The spire-server pods may be in a CrashLoopBackOff state.
  API calls to services may fail with HTTP 503 errors.
  The spire-server pods contain the following error in the logs.</description>
    </item>
    
    <item>
      <title>Ssl Certificate Validation Issues</title>
      <link>/docs-csm/en-13/troubleshooting/known_issues/ssl_certificate_validation_issues/</link>
      <pubDate>Sun, 11 Sep 2022 03:48:08 +0000</pubDate>
      
      <guid>/docs-csm/en-13/troubleshooting/known_issues/ssl_certificate_validation_issues/</guid>
      <description>SSL Certificate Validation Issues 1 SSL validation fails during the installation process If the intermediate CA that is used to sign service certificates changes after the NCNs are brought up, then this causes the platform-ca on the NCNs to no longer be valid. This is due to the platform-ca only being pulled via cloud-init on first boot. Run the following Goss test to validate this is the case.
1.1 Error messages /opt/cray/tests/ncn-resources/hms/hms-test/hms_run_ct_smoke_tests_ncn-resources.</description>
    </item>
    
    <item>
      <title>Cray Cli 403 Forbidden Errors</title>
      <link>/docs-csm/en-13/troubleshooting/known_issues/craycli_403_forbidden_errors/</link>
      <pubDate>Sun, 11 Sep 2022 03:48:07 +0000</pubDate>
      
      <guid>/docs-csm/en-13/troubleshooting/known_issues/craycli_403_forbidden_errors/</guid>
      <description>Cray CLI 403 Forbidden Errors There is a known issue where the Keycloak configuration obtained from LDAP is incomplete causing the keycloak-users-localize job to fail to complete. This, in turn, causes 403 Forbidden errors when trying to use the cray CLI. This can also cause a Keycloak test to fail during CSM health validation.
Fix To recover from this situation, the following can be done.
  Log into the Keycloak admin console.</description>
    </item>
    
    <item>
      <title>Gigabyte BMC Missing Redfish Data</title>
      <link>/docs-csm/en-13/troubleshooting/known_issues/gigabye_missing_redfish_data/</link>
      <pubDate>Sun, 11 Sep 2022 03:48:07 +0000</pubDate>
      
      <guid>/docs-csm/en-13/troubleshooting/known_issues/gigabye_missing_redfish_data/</guid>
      <description>Gigabyte BMC Missing Redfish Data Follow this procedure if you notice data from Gigabyte nodes is missing from Hardware State Manager (HSM) or other CSM tools.
If data from Gigabyte nodes is missing from HSM or other CSM tools, check the Redfish endpoint on the BMC to see if the data is present.
If the data is not present in the Redfish, then a cold reset of the BMC is needed to refresh the Redfish values.</description>
    </item>
    
    <item>
      <title>Hms Discovery Job Not Creating Redfishendpoints In Hardware State Manager</title>
      <link>/docs-csm/en-13/troubleshooting/known_issues/discovery_job_not_creating_redfish_endpoints/</link>
      <pubDate>Sun, 11 Sep 2022 03:48:07 +0000</pubDate>
      
      <guid>/docs-csm/en-13/troubleshooting/known_issues/discovery_job_not_creating_redfish_endpoints/</guid>
      <description>HMS Discovery Job Not Creating RedfishEndpoints In Hardware State Manager It is a known issue with the HMS Discovery cronjob that when a BMC does not respond by its IP address, the discovery job will not create a RedfishEndpoint for the BMC in Hardware State Manager (HSM). However, it does update the BMC MAC address in HSM with its component name (xname). The discovery job only creates a new RedfishEndpoints when it encounters an unknown MAC address without a component name (xname) associated with it.</description>
    </item>
    
    <item>
      <title>Known Issue Admin-client-auth Not Found</title>
      <link>/docs-csm/en-13/troubleshooting/known_issues/admin_client_auth_not_found/</link>
      <pubDate>Sun, 11 Sep 2022 03:48:07 +0000</pubDate>
      
      <guid>/docs-csm/en-13/troubleshooting/known_issues/admin_client_auth_not_found/</guid>
      <description>Known Issue: admin-client-auth Not Found Running the Install CSM Services script, the following error may occur:
ERROR Step: Set Management NCNs to use Unbound --- Checking Precondition + Getting admin-client-auth secret Error from server (NotFound): secrets &amp;#34;admin-client-auth&amp;#34; not found + Obtaining access token Fix This can occur if the keycloak-users-localize pod has not completed, and that can be caused by an intermittent Istio issue. Remediate the issue with the following procedure:</description>
    </item>
    
    <item>
      <title>Known Issue Initrd.img.xz Not Found</title>
      <link>/docs-csm/en-13/troubleshooting/known_issues/initrd.img.zx_not_found/</link>
      <pubDate>Sun, 11 Sep 2022 03:48:07 +0000</pubDate>
      
      <guid>/docs-csm/en-13/troubleshooting/known_issues/initrd.img.zx_not_found/</guid>
      <description>Known Issue: initrd.img.xz Not Found This is a problem that is fixed in CSM 1.0 and later, but if your system was upgraded from CSM 0.9 you may run into this. Below is the full error seen when attempting to boot:
Loading Linux ... Loading initial ramdisk ... error: file `/boot/grub2/../initrd.img.xz&#39; not found. Press any key to continue... [ 2.528752] Kernel panic - not syncing: VFS: Unable to mount root fs on unknown-block(0,0) [ 2.</description>
    </item>
    
    <item>
      <title>Known Issues With NCN Health Checks</title>
      <link>/docs-csm/en-13/troubleshooting/known_issues/issues_with_ncn_health_checks/</link>
      <pubDate>Sun, 11 Sep 2022 03:48:07 +0000</pubDate>
      
      <guid>/docs-csm/en-13/troubleshooting/known_issues/issues_with_ncn_health_checks/</guid>
      <description>Known issues with NCN health checks   The first pass of running these tests may fail due to cloud-init not being completed on the storage nodes. In the case of failure, wait for five minutes and rerun the tests.
  For any failures related to SSL certificates, see the SSL Certificate Validation Issues troubleshooting guide.
  Kubernetes Query BSS Cloud-init for ca-certs
 This test may fail immediately after platform installation.</description>
    </item>
    
    <item>
      <title>SAT/HSM/CAPMC Component Power State Mismatch</title>
      <link>/docs-csm/en-13/troubleshooting/known_issues/component_power_state_mismatch/</link>
      <pubDate>Sun, 11 Sep 2022 03:48:07 +0000</pubDate>
      
      <guid>/docs-csm/en-13/troubleshooting/known_issues/component_power_state_mismatch/</guid>
      <description>SAT/HSM/CAPMC Component Power State Mismatch Because of various hardware or communication issues, the node state reported by SAT and HSM (Hardware State Manager) may become out of sync with the actual hardware state reported by CAPMC or Redfish. In most cases this will be noticed when trying to power on or off nodes with BOS/BOA, and will present as SAT or HSM reporting nodes are On while CAPMC reports them as Off (or vice versa).</description>
    </item>
    
    <item>
      <title>SLS Not Working During Node Rebuild</title>
      <link>/docs-csm/en-13/troubleshooting/known_issues/sls_not_working_during_node_rebuild/</link>
      <pubDate>Sun, 11 Sep 2022 03:48:07 +0000</pubDate>
      
      <guid>/docs-csm/en-13/troubleshooting/known_issues/sls_not_working_during_node_rebuild/</guid>
      <description>SLS Not Working During Node Rebuild During some node rebuilds (including those that happen during Stage 1 and Stage 2 of the CSM upgrade process), the SLS Postgres database gets into a bad state, causing SLS to become unhealthy. This page outlines how to detect if this has happened and provides a remediation procedure.
Note: If encountering this during a CSM upgrade, then at this point of the upgrade process, the system has not yet upgraded the CSM services themselves.</description>
    </item>
    
  </channel>
</rss>
